{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib as urllib\n",
    "import gradio as gr\n",
    "import json\n",
    "import openai\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import configparser\n",
    "import time\n",
    "from astral import sun,Observer\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "\n",
    "openai.api_key =config['DEFAULT']['openai_api_key']\n",
    "#weather_api_key = config['DEFAULT']['weather_api_key']\n",
    "\n",
    "memcache=None\n",
    "\n",
    "startUpTime = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clearMemcache(memcache):\n",
    "    if len(memcache)==0:\n",
    "        return memcache\n",
    "    for k in memcache.keys():\n",
    "        if ((dt.datetime.now()-memcache[thisKey]['timestamp']).seconds)/60>10:\n",
    "            del(memcache[k])\n",
    "    return memcache\n",
    "\n",
    "\n",
    "def checkMemcache(memcache,thisKey):\n",
    "    if thisKey in memcache:\n",
    "        if ((dt.datetime.now()-memcache[thisKey]['timestamp']).seconds)/60<10:\n",
    "            return memcache[thisKey]['content']\n",
    "    return None\n",
    "\n",
    "def loadMemcache(memcache,thisKey,content):\n",
    "    memcache[thisKey]={}\n",
    "    memcache[thisKey]['timestamp']=dt.datetime.now()\n",
    "    memcache[thisKey]['content']=content\n",
    "    saveMemcache(memcache)\n",
    "    return memcache\n",
    "\n",
    "def saveMemcache(memcache):\n",
    "    file = open('memcache', 'wb')\n",
    "    memcache = pickle.dump(memcache, file)\n",
    "    file.close()\n",
    "\n",
    "if memcache is None:\n",
    "    try:\n",
    "        file = open('memcache', 'rb')\n",
    "        memcache = pickle.load(file)\n",
    "        file.close()\n",
    "        clearMemcache(memcache)\n",
    "    except:\n",
    "        memcache={}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8f9f666b764e1dbee44c7ff209b6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6655f34ecec4aaabd5f8a828d293141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/17.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47475b651e30423bbba82b8d7e88666d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataset = load_dataset(\"scikit-learn/auto-mpg\")\n",
    "df=pd.DataFrame(dataset['train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def aggGroupBy(target,groupList=None,functionList=['mean'],filterConditions=None,precision=2):\n",
    "    if type(groupList)!=list:\n",
    "        groupList = [groupList]\n",
    "    if type(functionList)!=list:\n",
    "        functionList=[functionList]\n",
    "    if groupList is None:\n",
    "        report=df.agg({target:functionList}).round(precision)\n",
    "    if filterConditions is None:\n",
    "        report=df.groupby(groupList).agg({target:functionList}).round(precision)\n",
    "    else:\n",
    "        print(filterConditions)\n",
    "        report=df.groupby(groupList).agg({target:functionList}).round(precision)\n",
    "    return report.head(20)\n",
    "\n",
    "\n",
    "def minOrMaxCase(target,aggFunction):\n",
    "    if aggFunction == 'max':\n",
    "        rowOrder = False\n",
    "    else:\n",
    "        rowOrder=True\n",
    "    if target=='acceleration' and rowOrder==False:\n",
    "        rowOrder = True\n",
    "    elif target=='acceleration':\n",
    "        rowOrder = False\n",
    "    report=df.sort_values(target,ascending=rowOrder).head(1)\n",
    "    report = json.dumps(report.to_dict(orient='records')[0])\n",
    "    return report\n",
    "\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"aggGroupBy\",\n",
    "        \"description\": '''Makes an aggregated report from the dataset.\n",
    "          Lets the user specify a variable to be analyzed, one or more grouping variables, \n",
    "          and one or more functions.  You can also use pandas to filter the dataframe\n",
    "          by specifying filterConditions.''',\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"groupList\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"List of variable names to group by\",\n",
    "                },\n",
    "                \"target\": {\"type\": \"string\",\"description\":\"the variable name to be analyzed and aggregated\"},\n",
    "            },\n",
    "            \"functionList\": {\"type\": \"string\",\"description\":\"list of pandas aggregation functions\"},\n",
    "            \n",
    "            \"filterConditions\": {\"type\": \"string\",\"description\":\"pandas where conditions to filter the dataset with\"},\n",
    "            },\n",
    "            \"required\": [\"target\"],\n",
    "        },\n",
    "    {\n",
    "        \"name\": \"minOrMaxCase\",\n",
    "        \"description\": '''Finds one case from the dataframe with a max or min value on the specified target variable.''',\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"aggFunction\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Specifies if the user wants the argmax or argmin.  return either 'min' or 'max'\",\n",
    "                },\n",
    "                \"target\": {\"type\": \"string\",\"description\":\"the variable name to be analyzed and aggregated\"},\n",
    "            },\n",
    "            \"functionList\": {\"type\": \"string\",\"description\":\"list of pandas aggregation functions\"},\n",
    "            \n",
    "            \"filterConditions\": {\"type\": \"string\",\"description\":\"pandas where conditions to filter the dataset with\"},\n",
    "            },\n",
    "            \"required\": [\"target\"],\n",
    "        }\n",
    "    \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = ','.join(list(df.columns))\n",
    "\n",
    "\n",
    "messages = [\n",
    "        {  \n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a helpful assistant that analyzes a dataset for the user. You can use\n",
    "        function calls to get data, or respond in sentences when proovided the data.\n",
    "        If you don't know how to apply to a function, apoligize and say you don't know how to do that.\n",
    "          You can answer questions about these variable names :\"\"\"+varnames+\"\"\"\n",
    "        All parameter values must be one of the specified variable names.\n",
    "        Do not make up information, and keep your responses concise.\n",
    "        If you identify the need to reply with a function call, but some required parameter are missing,\n",
    "          reply with a follow up question asking for missing parameters\"\"\"\n",
    "    },\n",
    "    {'role':\"user\",\n",
    "     'content':\"Make a report of mileage by number of cylinders. Give me average, min and max mileage per number of cylinders.\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'function_call'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#messages.append({'role':'user','content':'what is the average mileage by year?'})\n",
    "response = callLLM(messages,functions)\n",
    "cr = classifyReponse(response)\n",
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run a function to check if its got the right info, and send back if the function call doesnt make sense.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groupList': 'cylinders', 'target': 'mpg'} aggGroupBy\n"
     ]
    }
   ],
   "source": [
    "f = response['choices'][0]['message']['function_call']['name']\n",
    "kwargs = response['choices'][0]['message']['function_call']['arguments']\n",
    "kwargs = json.loads(kwargs)\n",
    "print(kwargs,f)\n",
    "function_response = globals()[f](**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groupList': 'cylinders', 'target': 'mpg'}\n",
      "             mpg\n",
      "            mean\n",
      "cylinders       \n",
      "3          20.55\n",
      "4          29.29\n",
      "5          27.37\n",
      "6          19.99\n",
      "8          14.96\n"
     ]
    }
   ],
   "source": [
    "print(kwargs)\n",
    "print(function_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('<U260'), dtype('float64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[308], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124;43m'''\u001b[39;49m\u001b[38;5;124;43muse the following data to concisely answer the user\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms question above accurately.\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43m                 Provide one or two other interesting facts from the JSON data.\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m                 Do not use a function call, but response with the data included here in JSON:JSON:\u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mfunction_response\u001b[49m})\n\u001b[1;32m      4\u001b[0m response \u001b[38;5;241m=\u001b[39m callLLM(messages,functions)\n\u001b[1;32m      5\u001b[0m cr \u001b[38;5;241m=\u001b[39m classifyReponse(response)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/arraylike.py:106\u001b[0m, in \u001b[0;36mOpsMixin.__radd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__radd__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__radd__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:7594\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7590\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[1;32m   7592\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_FRAME(\u001b[38;5;28mself\u001b[39m, other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 7594\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_frame_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7595\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:7621\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[0;34m(self, right, func, axis)\u001b[0m\n\u001b[1;32m   7618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(right):\n\u001b[1;32m   7619\u001b[0m     \u001b[38;5;66;03m# i.e. scalar, faster than checking np.ndim(right) == 0\u001b[39;00m\n\u001b[1;32m   7620\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 7621\u001b[0m         bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(bm)\n\u001b[1;32m   7624\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, DataFrame):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:350\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callable(f):\n\u001b[0;32m--> 350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/blocks.py:351\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:226\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    222\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:165\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    162\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/roperator.py:11\u001b[0m, in \u001b[0;36mradd\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mradd\u001b[39m(left, right):\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mright\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('<U260'), dtype('float64')) -> None"
     ]
    }
   ],
   "source": [
    "messages.append({'role':'system','content':'''use the following data to concisely answer the user's question above accurately.\n",
    "                 Provide one or two other interesting facts from the JSON data.\n",
    "                 Do not use a function call, but response with the data included here in JSON:JSON:'''+function_response})\n",
    "response = callLLM(messages,functions)\n",
    "cr = classifyReponse(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'content'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The slowest car in the dataset has a \"acceleration\" value of 24.8. It is a 1979 Peugeot 504 from origin 2.'"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newContent = response['choices'][0]['message']['content']\n",
    "newContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"mpg\": 14.0, \"cylinders\": 8, \"displacement\": 340.0, \"horsepower\": \"160\", \"weight\": 3609, \"acceleration\": 8.0, \"model year\": 70, \"origin\": 1, \"car name\": \"plymouth \\'cuda 340\"}'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json.dumps(df.sort_values('mpg',ascending=True).head(1).to_dict(orient='rows')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearItOut():\n",
    "    global messages\n",
    "    messages = [\n",
    "        {  \n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a helpful assistant that advises a user on how to dress for running, based on the current weather.\n",
    "          Only include information from the defined functions.\n",
    "        Do not make up information, and keep your responses concise.\"\"\"\n",
    "    }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def classifyReponse(response):\n",
    "    if response['choices'][0]['message']['content'] is not None:\n",
    "        return 'content'\n",
    "    elif 'function_call' in response['choices'][0]['message']:\n",
    "        return 'function_call'\n",
    "    \n",
    "def prepResponse(response):\n",
    "    cr = classifyReponse(response)\n",
    "    print(\"classified as \",cr)\n",
    "    if cr=='function_call':\n",
    "        f = response['choices'][0]['message']['function_call']['name']\n",
    "        kwargs = response['choices'][0]['message']['function_call']['arguments']\n",
    "        function_response = globals()[f](kwargs)\n",
    "        #return formatted message and logic to call llm again\n",
    "        message = {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": f,\n",
    "            \"content\": ','.join(function_response),\n",
    "        }\n",
    "        action = 'llm'\n",
    "        bot_message = None\n",
    "    elif cr=='content':\n",
    "        newContent = response['choices'][0]['message']['content']\n",
    "        #return formatted message and logic to send to ui\n",
    "        message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": newContent,\n",
    "        }\n",
    "        action = 'ui'\n",
    "        bot_message = newContent\n",
    "    return bot_message, message,action\n",
    "\n",
    "def callLLM(messages,functions):\n",
    "    raw_message = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=messages,\n",
    "                functions = functions\n",
    "            )\n",
    "    return raw_message\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "with gr.Blocks(title=\"RunGearGuru\",theme= \"gstaff/whiteboard\") as demo:\n",
    "    gr.Markdown(\"Use the textbox below to submit your question to the Guru.\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(\"What should i wear running in buffalo?\") \n",
    "    clear = gr.Button(\"Clear\")\n",
    "    gr.Markdown(\"To learn about this demo, go to my Github at https://github.com/jonathanmanly/runGearGuru\")\n",
    "\n",
    "    def user(user_message, history):\n",
    "        if ((dt.datetime.now()-startUpTime).seconds)/60>10:\n",
    "            clearItOut()\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history):\n",
    "        raw_message=' '\n",
    "        messages.append({'role':'user',\"content\":history[-1][0]})\n",
    "        raw_message = callLLM(messages,functions)\n",
    "        print(raw_message)\n",
    "        bot_message, history_message,action = prepResponse(raw_message)\n",
    "        #print(2)\n",
    "        messages.append(history_message)\n",
    "        #print(3)\n",
    "        if action =='llm':\n",
    "            raw_message = callLLM(messages,functions)\n",
    "            #print(4)\n",
    "            bot_message, history_message,action = prepResponse(raw_message)\n",
    "            #print(5)\n",
    "            #print(\"at function call\")\n",
    "            #print(bot_message,history_message,action)\n",
    "            messages.append(history_message)\n",
    "\n",
    "            \n",
    "        #determine here if it is function or content, then call function and produce content if so\n",
    "        #bot_message = raw_message['choices'][0]['message']['content']\n",
    "        #messages.append({\"role\":\"assistant\",\"content\":bot_message})\n",
    "        \n",
    "        history[-1][1] = \"\"\n",
    "        for character in bot_message:\n",
    "            history[-1][1] += character\n",
    "            time.sleep(0.001)\n",
    "            yield history\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    #clear.click(lambda: None, None, chatbot, queue=False)\n",
    "    clear.click(clearItOut, None, chatbot, queue=False)\n",
    "    \n",
    "demo.queue()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
