{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib as urllib\n",
    "import gradio as gr\n",
    "import json\n",
    "import openai\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import configparser\n",
    "import time\n",
    "from astral import sun,Observer\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "\n",
    "openai.api_key =config['DEFAULT']['openai_api_key']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_dataset(\"scikit-learn/auto-mpg\")\n",
    "df=pd.DataFrame(dataset['train'])\n",
    "\n",
    "\n",
    "dsInfo = \"car mpg statistics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def aggGroupBy(target,groupList=None,functionList=['mean'],filterConditions=None,precision=2):\n",
    "    if ',' in functionList:\n",
    "        functionList=functionList.split(',')\n",
    "    if type(groupList)!=list:\n",
    "        groupList = [groupList]\n",
    "    if type(functionList)!=list:\n",
    "        functionList=[functionList]\n",
    "    if groupList is None:\n",
    "        report=df.agg({target:functionList}).round(precision)\n",
    "    if filterConditions is None:\n",
    "        report=df.groupby(groupList).agg({target:functionList}).round(precision)\n",
    "    else:\n",
    "        print(filterConditions)\n",
    "        report=df.groupby(groupList).agg({target:functionList}).round(precision)\n",
    "    return report.head(20).to_csv()\n",
    "\n",
    "\n",
    "def minOrMaxCase(target,aggFunction):\n",
    "    if aggFunction == 'max':\n",
    "        rowOrder = False\n",
    "    else:\n",
    "        rowOrder=True\n",
    "    if target=='acceleration' and rowOrder==False:\n",
    "        rowOrder = True\n",
    "    elif target=='acceleration':\n",
    "        rowOrder = False\n",
    "    report=df.sort_values(target,ascending=rowOrder).head(1)\n",
    "    report = json.dumps(report.to_dict(orient='records')[0])\n",
    "    return report\n",
    "\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"aggGroupBy\",\n",
    "        \"description\": '''Makes an aggregated report from the dataset.\n",
    "          Lets the user specify a variable to be analyzed, one or more grouping variables, \n",
    "          and one or more aggregation functions from (min,max,mean,std).  You can also use pandas to filter the dataframe\n",
    "          by specifying filterConditions.''',\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"groupList\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"List of variable names to group by\",\n",
    "                },\n",
    "                \"target\": {\"type\": \"string\",\"description\":\"the variable name to be analyzed and aggregated\"},\n",
    "            \n",
    "            \"functionList\": {\"type\": \"string\",\"description\":\"list of pandas aggregation functions, chosen from min, max, mean, std\"},\n",
    "            \n",
    "            \"filterConditions\": {\"type\": \"string\",\"description\":\"pandas where conditions to filter the dataset with\"},\n",
    "            },},\n",
    "            \"required\": [\"target\", \"functionList\"],\n",
    "        },\n",
    "    {\n",
    "        \"name\": \"minOrMaxCase\",\n",
    "        \"description\": '''Finds one case from the dataframe with a max or min value on the specified target variable.''',\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"aggFunction\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Specifies if the user wants the argmax or argmin.  return either 'min' or 'max'\",\n",
    "                },\n",
    "                \"target\": {\"type\": \"string\",\"description\":\"the variable name to be analyzed and aggregated\"},\n",
    "            },\n",
    "            \"aggregations\": {\"type\": \"string\",\"description\":\"list of pandas aggregation functions, including min, max\"},\n",
    "            \n",
    "            \"filterConditions\": {\"type\": \"string\",\"description\":\"pandas where conditions to filter the dataset with\"},\n",
    "            },\n",
    "            \"required\": [\"target\"],\n",
    "        }\n",
    "    \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = ','.join(list(df.columns))\n",
    "\n",
    "\n",
    "messages = [\n",
    "        {  \n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a helpful assistant that analyzes a dataset about \"\"\"+dsInfo+\"\"\"for the user. You can use\n",
    "        function calls to get data, or respond in sentences when proovided the data.\n",
    "        If you don't know how to apply to a function, apoligize and say you don't know how to do that.\n",
    "          You can answer questions about these variable names :\"\"\"+varnames+\"\"\"\n",
    "        All parameter values must be one of the specified variable names.\n",
    "        Do not make up information, and keep your responses concise.\n",
    "        If you identify the need to reply with a function call, but some required parameter are missing,\n",
    "          reply with a follow up question asking for missing parameters.\n",
    "          You can also answer questions about the dataset metadata, and explain statistical analyses.\"\"\"\n",
    "    },\n",
    "    {'role':\"user\",\n",
    "     'content':\"Make a report of mean and max displacement by number of cylinders. Aggregatte functions average, min and max mileage per number of cylinders.\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages.append({'role':'user','content':'what is the average mileage by year?'})\n",
    "response = callLLM(messages,functions)\n",
    "cr = classifyReponse(response)\n",
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run a function to check if its got the right info, and send back if the function call doesnt make sense.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = response['choices'][0]['message']['function_call']['name']\n",
    "kwargs = response['choices'][0]['message']['function_call']['arguments']\n",
    "kwargs = json.loads(kwargs)\n",
    "print(kwargs,f)\n",
    "function_response = globals()[f](**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kwargs)\n",
    "print(function_response)\n",
    "type(function_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({'role':'system','content':'''use the following data to concisely answer the user's question above accurately.\n",
    "                 Provide one or two other interesting facts from the JSON data.\n",
    "                 Do not use a function call, but response with the data included here in JSON:JSON:'''+function_response})\n",
    "response = callLLM(messages,functions)\n",
    "cr = classifyReponse(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json.dumps(df.sort_values('mpg',ascending=True).head(1).to_dict(orient='rows')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearItOut():\n",
    "    global messages\n",
    "    messages = [\n",
    "        {  \n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a helpful assistant that analyzes a dataset about \"\"\"+dsInfo+\"\"\"for the user. \n",
    "        If the user's question is not directly related to the dataset, politely reject it.\n",
    "        You can use function calls to get data, or respond in sentences when proovided the data.\n",
    "        If you don't know how to apply to a function, apoligize and say you don't know how to do that.\n",
    "          You can answer questions about these variable names :\"\"\"+varnames+\"\"\"\n",
    "        All parameter values must be one of the specified variable names.\n",
    "        Do not make up information, and keep your responses concise.\n",
    "        If you identify the need to reply with a function call, but some required parameter are missing,\n",
    "          reply with a follow up question asking for missing parameters.\n",
    "          You can also answer questions about the dataset metadata, and explain statistical analyses.\"\"\"\n",
    "    },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def classifyReponse(response):\n",
    "    if response['choices'][0]['message']['content'] is not None:\n",
    "        return 'content'\n",
    "    elif 'function_call' in response['choices'][0]['message']:\n",
    "        return 'function_call'\n",
    "    \n",
    "def prepResponse(response):\n",
    "    cr = classifyReponse(response)\n",
    "    print(\"classified as \",cr)\n",
    "    if cr=='function_call':\n",
    "        f = response['choices'][0]['message']['function_call']['name']\n",
    "        kwargs = json.loads(response['choices'][0]['message']['function_call']['arguments'])\n",
    "        function_response = globals()[f](**kwargs)\n",
    "        #return formatted message and logic to call llm again\n",
    "        message = {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": f,\n",
    "            \"content\": ','.join(function_response),\n",
    "        }\n",
    "        action = 'llm'\n",
    "        bot_message = None\n",
    "    elif cr=='content':\n",
    "        newContent = response['choices'][0]['message']['content']\n",
    "        #return formatted message and logic to send to ui\n",
    "        message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": newContent,\n",
    "        }\n",
    "        action = 'ui'\n",
    "        bot_message = newContent\n",
    "    return bot_message, message,action\n",
    "\n",
    "def callLLM(messages,functions):\n",
    "    raw_message = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=messages,\n",
    "                functions = functions, temperature = 0.\n",
    "            )\n",
    "    return raw_message\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "startUpTime = datetime.datetime.now()\n",
    "\n",
    "\n",
    "with gr.Blocks(title=\"Conversational BI Demo\",theme='YenLai/Superhuman') as demo:\n",
    "    gr.Markdown(\"Use the textbox below to ask questions about the dataset.\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(\"What is the car with the best mileage?\") \n",
    "    clear = gr.Button(\"Clear\")\n",
    "    gr.Markdown(\"To learn about this demo, go to my Github at https://github.com/jonathanmanly/runGearGuruconvBI\")\n",
    "\n",
    "    def user(user_message, history):\n",
    "        if ((dt.datetime.now()-startUpTime).seconds)/60>10:\n",
    "            clearItOut()\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history):\n",
    "        raw_message=''\n",
    "        messages.append({'role':'user',\"content\":history[-1][0]})\n",
    "        raw_message = callLLM(messages,functions)\n",
    "        print(raw_message)\n",
    "        bot_message, history_message,action = prepResponse(raw_message)\n",
    "        #print(2)\n",
    "        messages.append(history_message)\n",
    "        #print(3)\n",
    "        if action =='llm':\n",
    "            raw_message = callLLM(messages,functions)\n",
    "            #print(4)\n",
    "            bot_message, history_message,action = prepResponse(raw_message)\n",
    "            #print(5)\n",
    "            #print(\"at function call\")\n",
    "            #print(bot_message,history_message,action)\n",
    "            messages.append(history_message)\n",
    "\n",
    "            \n",
    "        #determine here if it is function or content, then call function and produce content if so\n",
    "        #bot_message = raw_message['choices'][0]['message']['content']\n",
    "        #messages.append({\"role\":\"assistant\",\"content\":bot_message})\n",
    "        \n",
    "        history[-1][1] = \"\"\n",
    "        for character in bot_message:\n",
    "            history[-1][1] += character\n",
    "            time.sleep(0.001)\n",
    "            yield history\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    #clear.click(lambda: None, None, chatbot, queue=False)\n",
    "    clear.click(clearItOut, None, chatbot, queue=False)\n",
    "    \n",
    "demo.queue()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
