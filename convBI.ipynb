{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import urllib as urllib\n",
    "import gradio as gr\n",
    "import json\n",
    "import openai\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import configparser\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "\n",
    "openai.api_key =config['DEFAULT']['openai_api_key']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_dataset(\"scikit-learn/auto-mpg\",split='train')\n",
    "df=pd.DataFrame(dataset)\n",
    "\n",
    "\n",
    "dsInfo = \"car mpg statistics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def aggGroupBy(target,groupList=None,functionList=['mean'],filterConditions=None,precision=2):\n",
    "    if ',' in functionList:\n",
    "        functionList=functionList.split(',')\n",
    "    if type(groupList)!=list:\n",
    "        groupList = [groupList]\n",
    "    if type(functionList)!=list:\n",
    "        functionList=[functionList]\n",
    "    if groupList is None:\n",
    "        report=df.agg({target:functionList}).round(precision)\n",
    "    if filterConditions is None:\n",
    "        report=df.groupby(groupList).agg({target:functionList}).round(precision)\n",
    "    else:\n",
    "        print(filterConditions)\n",
    "        report=df.groupby(groupList).agg({target:functionList}).round(precision)\n",
    "    return report.head(20).to_csv()\n",
    "\n",
    "\n",
    "def minOrMaxCase(target,aggFunction):\n",
    "    if aggFunction == 'max':\n",
    "        rowOrder = False\n",
    "    else:\n",
    "        rowOrder=True\n",
    "    if target=='acceleration' and rowOrder==False:\n",
    "        rowOrder = True\n",
    "    elif target=='acceleration':\n",
    "        rowOrder = False\n",
    "    report=df.sort_values(target,ascending=rowOrder).head(1)\n",
    "    report = json.dumps(report.to_dict(orient='records')[0])\n",
    "    return report\n",
    "\n",
    "\n",
    "def multipleRegression(indVar=['displacement'],depVar='mpg'):\n",
    "    if type(indVar) !=list:\n",
    "        indVar = [indVar]\n",
    "    y=df[depVar].values.reshape(-1,1)\n",
    "    X=df[indVar]#.values.reshape(-1,1)\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    score = round(reg.score(X, y),3)\n",
    "    coef = reg.coef_\n",
    "    intercept = round(reg.intercept_[0],3)\n",
    "    formula = depVar+\" = \"+str(intercept)+' '\n",
    "    for z in zip(coef[0],indVar):\n",
    "        if z[0]>0:\n",
    "            formula=formula+\"+\"\n",
    "        formula = formula+str(z[0].round(3))+\"*\"+z[1]+' '\n",
    "    report = f\"\"\"The independent variable(s) explain {score} of the variance in {depVar}. \\n\n",
    "            The R2 or R-squared value is {depVar}.\n",
    "            The regression formula is {formula}\"\"\"\n",
    "    return report\n",
    "\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"aggGroupBy\",\n",
    "        \"description\": '''Makes an aggregated report from the dataset.\n",
    "          Lets the user specify a variable to be analyzed, one or more grouping variables, \n",
    "          and one or more aggregation functions from (min,max,mean,std).  You can also use pandas to filter the dataframe\n",
    "          by specifying filterConditions.''',\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"groupList\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"List of variable names to group by\",\n",
    "                },\n",
    "                \"target\": {\"type\": \"string\",\"description\":\"the variable name to be analyzed and aggregated\"},\n",
    "            \n",
    "            \"functionList\": {\"type\": \"string\",\"description\":\"list of pandas aggregation functions, chosen from min, max, mean, std\"},\n",
    "            \n",
    "            \"filterConditions\": {\"type\": \"string\",\"description\":\"pandas where conditions to filter the dataset with\"},\n",
    "            },},\n",
    "            \"required\": [\"target\", \"functionList\"],\n",
    "        },\n",
    "    {\n",
    "        \"name\": \"minOrMaxCase\",\n",
    "        \"description\": '''Finds one case from the dataframe with a max or min value on the specified target variable.''',\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"aggFunction\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Specifies if the user wants the argmax or argmin.  return either 'min' or 'max'\",\n",
    "                },\n",
    "                \"target\": {\"type\": \"string\",\"description\":\"the variable name to be analyzed and aggregated\"},\n",
    "            },\n",
    "            \"aggregations\": {\"type\": \"string\",\"description\":\"list of pandas aggregation functions, including min, max\"},\n",
    "            \n",
    "            \"filterConditions\": {\"type\": \"string\",\"description\":\"pandas where conditions to filter the dataset with\"},\n",
    "            },\n",
    "            \"required\": [\"target\"],\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"multipleRegression\",\n",
    "        \"description\": '''runs a linear multiple regression to determine the linear relationship between the dependent \\n\n",
    "                            target variable and one or more independent explanatory variables. \\n\n",
    "                            Returns the R2 (R-squared) value and the linear formula.''',\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"indVar\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"one or more independent variables to explain the dependent variable via linear multiple regression\",\n",
    "                },\n",
    "                \"depVar\": {\"type\": \"string\",\"description\":\"one variable to be explained by regression by the independent variable(s)\"},\n",
    "            },\n",
    "            },\n",
    "            \"required\": [\"indVar\",\"depVar\"],\n",
    "        }\n",
    "    \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = ','.join(list(df.columns))\n",
    "\n",
    "\n",
    "initialMessages = [\n",
    "        {  \n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a helpful assistant that analyzes a dataset about \"\"\"+dsInfo+\"\"\"for the user. \n",
    "        If the user's question is not directly related to the dataset, politely reject it.\n",
    "        You can use function calls to get data, or respond in sentences when proovided the data.\n",
    "        If you don't know how to apply to a function, apoligize and say you don't know how to do that.\n",
    "          You can answer questions about these variable names :\"\"\"+varnames+\"\"\"\n",
    "        All parameter values must be one of the specified variable names.\n",
    "        Do not make up information, and keep your responses concise.\n",
    "        If you identify the need to reply with a function call, but some required parameter are missing,\n",
    "          reply with a follow up question asking for missing parameters.\n",
    "          You can also answer questions about the dataset metadata, and explain statistical analyses.\"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "messages = initialMessages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages.append({'role':'user','content':'what regression relationship between mpg and number of cylinders?'})\n",
    "#response = callLLM(messages,functions)\n",
    "#cr = classifyReponse(response)\n",
    "#cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#f = response['choices'][0]['message']['function_call']['name']\n",
    "#kwargs = response['choices'][0]['message']['function_call']['arguments']\n",
    "#kwargs = json.loads(kwargs)\n",
    "#print(kwargs,f)\n",
    "#function_response = globals()[f](**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(kwargs)\n",
    "#print(function_response)\n",
    "#type(function_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#messages.append({'role':'system','content':'''use the following data to concisely answer the user's question above accurately.\n",
    "#                 Provide one or two other interesting facts from the JSON data.\n",
    "#                 Do not use a function call, but response with the data included here in JSON:JSON:'''+function_response})\n",
    "#response = callLLM(messages,functions)\n",
    "#cr = classifyReponse(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearItOut():\n",
    "    global messages\n",
    "    messages = initialMessages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def classifyReponse(response):\n",
    "    if response['choices'][0]['message']['content'] is not None:\n",
    "        return 'content'\n",
    "    elif 'function_call' in response['choices'][0]['message']:\n",
    "        return 'function_call'\n",
    "    \n",
    "def prepResponse(response):\n",
    "    cr = classifyReponse(response)\n",
    "    print(\"classified as \",cr)\n",
    "    if cr=='function_call':\n",
    "        f = response['choices'][0]['message']['function_call']['name']\n",
    "        kwargs = json.loads(response['choices'][0]['message']['function_call']['arguments'])\n",
    "        function_response = globals()[f](**kwargs)\n",
    "        #return formatted message and logic to call llm again\n",
    "        message = {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": f,\n",
    "            \"content\": ','.join(function_response),\n",
    "        }\n",
    "        action = 'llm'\n",
    "        bot_message = None\n",
    "    elif cr=='content':\n",
    "        newContent = response['choices'][0]['message']['content']\n",
    "        #return formatted message and logic to send to ui\n",
    "        message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": newContent,\n",
    "        }\n",
    "        action = 'ui'\n",
    "        bot_message = newContent\n",
    "    return bot_message, message,action\n",
    "\n",
    "def callLLM(messages,functions):\n",
    "    raw_message = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=messages,\n",
    "                functions = functions, temperature = 0.\n",
    "            )\n",
    "    return raw_message\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "startUpTime = dt.datetime.now()\n",
    "\n",
    "\n",
    "with gr.Blocks(title=\"Conversational BI Demo\",theme='YenLai/Superhuman') as demo:\n",
    "    gr.Markdown(\"Use the textbox below to ask questions about the dataset.\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(\"What is the car with the best mileage?\") \n",
    "    clear = gr.Button(\"Clear\")\n",
    "    gr.Markdown(\"To learn about this demo, go to my Github at https://github.com/jonathanmanly/runGearGuruconvBI\")\n",
    "\n",
    "    def user(user_message, history):\n",
    "        if ((dt.datetime.now()-startUpTime).seconds)/60>10:\n",
    "            clearItOut()\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history):\n",
    "        raw_message=''\n",
    "        messages.append({'role':'user',\"content\":history[-1][0]})\n",
    "        raw_message = callLLM(messages,functions)\n",
    "        print(raw_message)\n",
    "        bot_message, history_message,action = prepResponse(raw_message)\n",
    "        #print(2)\n",
    "        messages.append(history_message)\n",
    "        #print(3)\n",
    "        if action =='llm':\n",
    "            raw_message = callLLM(messages,functions)\n",
    "            #print(4)\n",
    "            bot_message, history_message,action = prepResponse(raw_message)\n",
    "            #print(5)\n",
    "            #print(\"at function call\")\n",
    "            #print(bot_message,history_message,action)\n",
    "            messages.append(history_message)\n",
    "\n",
    "            \n",
    "        #determine here if it is function or content, then call function and produce content if so\n",
    "        #bot_message = raw_message['choices'][0]['message']['content']\n",
    "        #messages.append({\"role\":\"assistant\",\"content\":bot_message})\n",
    "        \n",
    "        history[-1][1] = \"\"\n",
    "        for character in bot_message:\n",
    "            history[-1][1] += character\n",
    "            time.sleep(0.001)\n",
    "            yield history\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    #clear.click(lambda: None, None, chatbot, queue=False)\n",
    "    clear.click(clearItOut, None, chatbot, queue=False)\n",
    "    \n",
    "demo.queue()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
